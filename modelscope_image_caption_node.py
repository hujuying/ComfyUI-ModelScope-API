import requests
import json
import time
import torch
import numpy as np
from PIL import Image
from io import BytesIO
import os
import base64
import re
from .modelscope_image_node import load_config, load_api_tokens, save_api_tokens, tensor_to_base64_url

# æ£€æŸ¥openaiåº“æ˜¯å¦å¯ç”¨
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

class ModelScopeImageCaptionNode:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        if not OPENAI_AVAILABLE:
            return {
                "required": {
                    "error_message": ("STRING", {
                        "default": "è¯·å…ˆå®‰è£…openaiåº“: pip install openai",
                        "multiline": True
                    }),
                }
            }
        saved_tokens = load_api_tokens()
        # å®šä¹‰æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨
        supported_models = [
            "Qwen/Qwen3-VL-8B-Instruct",
            "Qwen/Qwen3-VL-235B-A22B-Instruct"
        ]
        return {
            "required": {
                "image": ("IMAGE",),
                "api_tokens": ("STRING", {
                    "default": f"***å·²ä¿å­˜{len(saved_tokens)}ä¸ªToken***" if saved_tokens else "",
                    "placeholder": "è¯·è¾“å…¥API Tokenï¼ˆæ”¯æŒå¤šä¸ªï¼Œç”¨é€—å·/æ¢è¡Œåˆ†éš”ï¼‰",
                    "multiline": True
                }),
            },
            "optional": {
                "prompt1": ("STRING", {
                    "multiline": True,
                    "default": "è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»ä½“ã€èƒŒæ™¯ã€é¢œè‰²ã€é£æ ¼ç­‰ä¿¡æ¯"
                }),
                "prompt2": ("STRING", {
                    "multiline": True,
                    "default": ""
                }),
                # æ·»åŠ æ¨¡å‹ä¸‹æ‹‰é€‰æ‹©
                "model": (supported_models, {
                    "default": "Qwen/Qwen3-VL-8B-Instruct"  # é»˜è®¤é€‰ä¸­åŸæ¨¡å‹
                }),
                "max_tokens": ("INT", {
                    "default": 1000,
                    "min": 100,
                    "max": 4000
                }),
                "temperature": ("FLOAT", {
                    "default": 0.7,
                    "min": 0.1,
                    "max": 2.0,
                    "step": 0.1
                }),
            }
        }

    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("description",)
    FUNCTION = "generate_caption"
    CATEGORY = "ModelScopeAPI"

    def parse_api_tokens(self, token_input):
        """è§£æè¾“å…¥çš„å¤šä¸ªAPI Tokenï¼ˆæ”¯æŒé€—å·ã€åˆ†å·ã€æ¢è¡Œåˆ†éš”ï¼‰"""
        if not token_input or token_input.strip() in ["", f"***å·²ä¿å­˜{len(load_api_tokens())}ä¸ªToken***"]:
            return load_api_tokens()
        
        # æ”¯æŒå¤šç§åˆ†éš”ç¬¦æ‹†åˆ†Token
        tokens = re.split(r'[,;\n]+', token_input)
        return [token.strip() for token in tokens if token.strip()]

    # è°ƒæ•´å‚æ•°é¡ºåºï¼ŒåŠ å…¥æ–°çš„prompt2å‚æ•°
    def generate_caption(self, image=None, api_tokens="", prompt1="è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹", prompt2="", model="Qwen/Qwen3-VL-8B-Instruct", max_tokens=1000, temperature=0.7):
        if not OPENAI_AVAILABLE:
            return ("è¯·å…ˆå®‰è£…openaiåº“: pip install openai",)
        
        # å¤„ç†æç¤ºè¯åˆå¹¶
        prompt_parts = []
        if prompt1.strip():
            prompt_parts.append(prompt1.strip())
        if prompt2.strip():
            prompt_parts.append(prompt2.strip())
        
        # å¦‚æœä¸¤ä¸ªæç¤ºè¯éƒ½ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤æç¤º
        if not prompt_parts:
            prompt = "è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼ŒåŒ…æ‹¬ä¸»ä½“ã€èƒŒæ™¯ã€é¢œè‰²ã€é£æ ¼ç­‰ä¿¡æ¯"
        else:
            prompt = ", ".join(prompt_parts)
        
        # è§£æTokenåˆ—è¡¨ï¼ˆæ”¯æŒå¤šä¸ªï¼‰
        tokens = self.parse_api_tokens(api_tokens)
        if not tokens:
            raise Exception("è¯·æä¾›è‡³å°‘ä¸€ä¸ªæœ‰æ•ˆçš„API Token")
        
        # ä¿å­˜æ–°Tokenï¼ˆå¦‚æœæœ‰å˜åŒ–ï¼‰
        saved_tokens = load_api_tokens()
        if api_tokens.strip() not in ["", f"***å·²ä¿å­˜{len(saved_tokens)}ä¸ªToken***"]:
            if save_api_tokens(tokens):
                print(f"âœ… å·²ä¿å­˜ {len(tokens)} ä¸ªAPI Token")
            else:
                print("âš ï¸ API Tokenä¿å­˜å¤±è´¥ï¼Œä½†ä¸å½±å“å½“å‰ä½¿ç”¨")
        
        try:
            print(f"ğŸ” å¼€å§‹ç”Ÿæˆå›¾åƒæè¿°...")
            print(f"ğŸ“ æç¤ºè¯: {prompt}")
            print(f"ğŸ¤– æ¨¡å‹: {model}")  # æ˜¾ç¤ºé€‰ä¸­çš„æ¨¡å‹
            print(f"ğŸ”‘ å¯ç”¨Tokenæ•°é‡: {len(tokens)}")
            
            # è½¬æ¢å›¾åƒä¸ºbase64æ ¼å¼
            image_url = tensor_to_base64_url(image)
            print(f"ğŸ–¼ï¸ å›¾åƒå·²è½¬æ¢ä¸ºbase64æ ¼å¼")
            
            # æ„å»ºæ¶ˆæ¯ä½“
            messages = [{
                'role': 'user',
                'content': [{
                    'type': 'text',
                    'text': prompt,
                }, {
                    'type': 'image_url',
                    'image_url': {
                        'url': image_url,
                    },
                }],
            }]
            
            # è½®è¯¢å°è¯•æ¯ä¸ªToken
            last_exception = None
            for i, token in enumerate(tokens):
                try:
                    print(f"ğŸ”„ å°è¯•ä½¿ç”¨ç¬¬ {i+1}/{len(tokens)} ä¸ªToken...")
                    
                    # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
                    client = OpenAI(
                        base_url='https://api-inference.modelscope.cn/v1',
                        api_key=token
                    )
                    
                    # è°ƒç”¨APIï¼ˆä½¿ç”¨é€‰ä¸­çš„æ¨¡å‹ï¼‰
                    response = client.chat.completions.create(
                        model=model,
                        messages=messages,
                        max_tokens=max_tokens,
                        temperature=temperature,
                        stream=False
                    )
                    
                    # æˆåŠŸè·å–ç»“æœ
                    description = response.choices[0].message.content
                    print(f"âœ… ç¬¬ {i+1} ä¸ªTokenè°ƒç”¨æˆåŠŸ!")
                    print(f"ğŸ“„ ç»“æœé¢„è§ˆ: {description[:100]}...")
                    return (description,)
                    
                except Exception as e:
                    last_exception = e
                    print(f"âŒ ç¬¬ {i+1} ä¸ªTokenè°ƒç”¨å¤±è´¥: {str(e)}")
                    if i < len(tokens) - 1:
                        print(f"â³ å‡†å¤‡å°è¯•ä¸‹ä¸€ä¸ªToken...")
            
            # æ‰€æœ‰Tokenéƒ½å¤±è´¥
            raise Exception(f"æ‰€æœ‰Tokenå‡è°ƒç”¨å¤±è´¥: {str(last_exception)}")
            
        except Exception as e:
            error_msg = f"å›¾åƒæè¿°ç”Ÿæˆå¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return (error_msg,)

# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ModelScopeImageCaptionNode": ModelScopeImageCaptionNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ModelScopeImageCaptionNode": "ModelScope å›¾åƒæè¿°ç”Ÿæˆ"
}
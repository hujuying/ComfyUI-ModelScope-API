import requests
import json
import time
import torch
import numpy as np
from PIL import Image
from io import BytesIO
import os
import folder_paths
import base64
import tempfile

def load_config():
    config_path = os.path.join(os.path.dirname(__file__), 'modelscope_config.json')
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except:
        return {
            "default_model": "Qwen/Qwen-Image",
            "timeout": 720,
            "image_download_timeout": 30,
            "default_prompt": "A beautiful landscape"
        }

def save_config(config: dict) -> bool:
    config_path = os.path.join(os.path.dirname(__file__), 'modelscope_config.json')
    try:
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
        return False

def save_api_tokens(tokens):
    """ä¿å­˜å¤šä¸ªAPI Token"""
    tokens_path = os.path.join(os.path.dirname(__file__), '.qwen_tokens')
    try:
        with open(tokens_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(tokens))  # æ¯ä¸ªtokenä¸€è¡Œ
    except Exception as e:
        print(f"ä¿å­˜tokenså¤±è´¥(.qwen_tokens): {e}")
    
    try:
        cfg = load_config()
        cfg["api_tokens"] = tokens
        if save_config(cfg):
            return True
        return False
    except Exception as e:
        print(f"ä¿å­˜tokenså¤±è´¥(config.json): {e}")
        return False

def load_api_tokens():
    """åŠ è½½å¤šä¸ªAPI Token"""
    tokens_path = os.path.join(os.path.dirname(__file__), '.qwen_tokens')
    try:
        cfg = load_config()
        tokens_from_cfg = cfg.get("api_tokens", [])
        if tokens_from_cfg and isinstance(tokens_from_cfg, list):
            return [token.strip() for token in tokens_from_cfg if token.strip()]
    except Exception as e:
        print(f"è¯»å–config.jsonä¸­çš„tokenså¤±è´¥: {e}")
    
    try:
        if os.path.exists(tokens_path):
            with open(tokens_path, 'r', encoding='utf-8') as f:
                tokens = [line.strip() for line in f.read().split('\n') if line.strip()]
                return tokens if tokens else []
        return []
    except Exception as e:
        print(f"åŠ è½½tokenså¤±è´¥: {e}")
        return []

def parse_api_tokens(token_input):
    """è§£æè¾“å…¥çš„API Tokensï¼ˆæ”¯æŒé€—å·ã€åˆ†å·ã€æ¢è¡Œåˆ†éš”ï¼‰"""
    if not token_input or token_input.strip() in ["", "***å·²ä¿å­˜***"]:
        return load_api_tokens()
    
    # æ”¯æŒå¤šç§åˆ†éš”ç¬¦
    import re
    tokens = re.split(r'[,;\n]+', token_input)
    return [token.strip() for token in tokens if token.strip()]

def tensor_to_base64_url(image_tensor):
    try:
        if len(image_tensor.shape) == 4:
            image_tensor = image_tensor.squeeze(0)
        
        if image_tensor.max() <= 1.0:
            image_np = (image_tensor.cpu().numpy() * 255).astype(np.uint8)
        else:
            image_np = image_tensor.cpu().numpy().astype(np.uint8)
        
        pil_image = Image.fromarray(image_np)
        
        buffer = BytesIO()
        pil_image.save(buffer, format='JPEG', quality=85)
        img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
        
        return f"data:image/jpeg;base64,{img_base64}"
        
    except Exception as e:
        print(f"å›¾åƒè½¬æ¢å¤±è´¥: {e}")
        raise Exception(f"å›¾åƒæ ¼å¼è½¬æ¢å¤±è´¥: {str(e)}")


class ModelScopeImageNode:
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        config = load_config()
        saved_tokens = load_api_tokens()
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": config.get("default_prompt", "A beautiful landscape")
                }),
                "api_tokens": ("STRING", {
                    "default": "***å·²ä¿å­˜{}ä¸ªToken***".format(len(saved_tokens)) if saved_tokens else "",
                    "placeholder": "è¯·è¾“å…¥API Tokenï¼ˆæ”¯æŒå¤šä¸ªï¼Œç”¨é€—å·/æ¢è¡Œåˆ†éš”ï¼‰" if not saved_tokens else "ç•™ç©ºä½¿ç”¨å·²ä¿å­˜çš„Token",
                    "multiline": True
                }),
            },
            "optional": {
                "model": (config.get("image_models", ["Qwen/Qwen-Image"]), {
                    "default": config.get("default_model", "Qwen/Qwen-Image")
                }),
                "negative_prompt": ("STRING", {
                    "multiline": True,
                    "default": config.get("default_negative_prompt", "")
                }),
                "width": ("INT", {
                    "default": config.get("default_width", 512),
                    "min": 64,
                    "max": 2048,
                    "step": 64
                }),
                "height": ("INT", {
                    "default": config.get("default_height", 512),
                    "min": 64,
                    "max": 2048,
                    "step": 64
                }),
                "seed": ("INT", {
                    "default": config.get("default_seed", -1),
                    "min": -1,
                    "max": 2147483647
                }),
                "steps": ("INT", {
                    "default": config.get("default_steps", 30),
                    "min": 1,
                    "max": 100
                }),
                "guidance": ("FLOAT", {
                    "default": config.get("default_guidance", 7.5),
                    "min": 1.5,
                    "max": 20.0,
                    "step": 0.1
                }),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    FUNCTION = "generate_image"
    CATEGORY = "ModelScopeAPI"
    
    def generate_image(self, prompt, api_tokens, model="Qwen/Qwen-Image", negative_prompt="", width=512, height=512, seed=-1, steps=30, guidance=7.5):
        config = load_config()
        tokens = parse_api_tokens(api_tokens)
        
        if not tokens:
            raise Exception("è¯·æä¾›è‡³å°‘ä¸€ä¸ªæœ‰æ•ˆçš„API Token")
        
        # ä¿å­˜Tokenï¼ˆå¦‚æœæä¾›äº†æ–°çš„ï¼‰
        if api_tokens and api_tokens.strip() not in ["", "***å·²ä¿å­˜{}ä¸ªToken***".format(len(load_api_tokens()))]:
            if save_api_tokens(tokens):
                print(f"âœ… å·²ä¿å­˜ {len(tokens)} ä¸ªAPI Token")
            else:
                print("âš ï¸ API Tokenä¿å­˜å¤±è´¥ï¼Œä½†ä¸å½±å“å½“å‰ä½¿ç”¨")
        
        # è½®è¯¢å°è¯•æ¯ä¸ªToken
        last_exception = None
        for i, token in enumerate(tokens):
            try:
                print(f"ğŸ”„ å°è¯•ä½¿ç”¨ç¬¬ {i+1} ä¸ªAPI Token...")
                url = 'https://api-inference.modelscope.cn/v1/images/generations'
                payload = {
                    'model': model,
                    'prompt': prompt,
                    'size': f"{width}x{height}",
                    'steps': steps,
                    'guidance': guidance
                }
                if negative_prompt.strip():
                    payload['negative_prompt'] = negative_prompt
                if seed != -1:
                    payload['seed'] = seed
                else:
                    import random
                    random_seed = random.randint(0, 2147483647)
                    payload['seed'] = random_seed
                
                headers = {
                    'Authorization': f'Bearer {token}',
                    'Content-Type': 'application/json',
                    'X-ModelScope-Async-Mode': 'true'
                }
                
                submission_response = requests.post(
                    url, 
                    data=json.dumps(payload, ensure_ascii=False).encode('utf-8'), 
                    headers=headers,
                    timeout=config.get("timeout", 60)
                )
                
                if submission_response.status_code == 400:
                    # å°è¯•ä½¿ç”¨æœ€å°å‚æ•°é‡è¯•
                    minimal_payload = {
                        'model': model,
                        'prompt': prompt
                    }
                    submission_response = requests.post(
                        url,
                        data=json.dumps(minimal_payload, ensure_ascii=False).encode('utf-8'),
                        headers=headers,
                        timeout=config.get("timeout", 60)
                    )
                
                if submission_response.status_code != 200:
                    raise Exception(f"APIè¯·æ±‚å¤±è´¥: {submission_response.status_code}, {submission_response.text}")
                
                submission_json = submission_response.json()
                image_url = None
                if 'task_id' in submission_json:
                    task_id = submission_json['task_id']
                    print(f"ğŸ•’ å·²æäº¤ä»»åŠ¡ï¼Œä»»åŠ¡ID: {task_id}ï¼Œå¼€å§‹è½®è¯¢...")
                    poll_start = time.time()
                    max_wait_seconds = max(60, config.get('timeout', 720))
                    while True:
                        task_resp = requests.get(
                            f"https://api-inference.modelscope.cn/v1/tasks/{task_id}",
                            headers={
                                'Authorization': f'Bearer {token}',
                                'X-ModelScope-Task-Type': 'image_generation'
                            },
                            timeout=config.get("image_download_timeout", 120)
                        )
                        if task_resp.status_code != 200:
                            raise Exception(f"ä»»åŠ¡æŸ¥è¯¢å¤±è´¥: {task_resp.status_code}, {task_resp.text}")
                        task_data = task_resp.json()
                        status = task_data.get('task_status')
                        if status == 'SUCCEED':
                            output_images = task_data.get('output_images') or []
                            if not output_images:
                                raise Exception("ä»»åŠ¡æˆåŠŸä½†æœªè¿”å›å›¾ç‰‡URL")
                            image_url = output_images[0]
                            print("âœ… ä»»åŠ¡å®Œæˆï¼Œå¼€å§‹ä¸‹è½½å›¾ç‰‡...")
                            break
                        if status == 'FAILED':
                            raise Exception(f"ä»»åŠ¡å¤±è´¥: {task_data}")
                        if time.time() - poll_start > max_wait_seconds:
                            raise Exception("ä»»åŠ¡è½®è¯¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•æˆ–é™ä½å¹¶å‘")
                        time.sleep(5)
                elif 'images' in submission_json and len(submission_json['images']) > 0:
                    image_url = submission_json['images'][0]['url']
                    print(f"â¬‡ï¸ ä¸‹è½½ç”Ÿæˆçš„å›¾ç‰‡...")
                else:
                    raise Exception(f"æœªè¯†åˆ«çš„APIè¿”å›æ ¼å¼: {submission_json}")
                
                img_response = requests.get(image_url, timeout=config.get("image_download_timeout", 30))
                if img_response.status_code != 200:
                    raise Exception(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_response.status_code}")
                
                pil_image = Image.open(BytesIO(img_response.content))
                if pil_image.mode != 'RGB':
                    pil_image = pil_image.convert('RGB')
                image_np = np.array(pil_image).astype(np.float32) / 255.0
                image_tensor = torch.from_numpy(image_np)[None,]
                print(f"ğŸ‰ å›¾ç‰‡å¤„ç†å®Œæˆï¼ä½¿ç”¨çš„ç¬¬ {i+1} ä¸ªAPI Token")
                return (image_tensor,)
                
            except Exception as e:
                last_exception = e
                print(f"âš ï¸ ç¬¬ {i+1} ä¸ªAPI Tokenå¤±è´¥: {str(e)}")
                if i < len(tokens) - 1:  # ä¸æ˜¯æœ€åä¸€ä¸ªToken
                    print(f"â¡ï¸ å°è¯•ä¸‹ä¸€ä¸ªAPI Token...")
                    continue
                else:
                    break  # æ‰€æœ‰Tokenéƒ½å¤±è´¥äº†
        
        # æ‰€æœ‰Tokenéƒ½å¤±è´¥
        raise Exception(f"æ‰€æœ‰ {len(tokens)} ä¸ªAPI Tokenéƒ½å¤±è´¥äº†ã€‚æœ€åçš„é”™è¯¯: {str(last_exception)}")


class ModelScopeImageEditNode:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        config = load_config()
        saved_tokens = load_api_tokens()
        
        # è·å–æ¨¡å‹åˆ—è¡¨
        edit_models = config.get("image_edit_models", ["Qwen/Qwen-Image-Edit"])
        gen_models = config.get("image_models", ["Qwen/Qwen-Image"])

        return {
            "required": {
                "image": ("IMAGE",),
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "ä¿®æ”¹å›¾ç‰‡ä¸­çš„å†…å®¹"
                }),
                "api_tokens": ("STRING", {
                    "default": "***å·²ä¿å­˜{}ä¸ªToken***".format(len(saved_tokens)) if saved_tokens else "",
                    "placeholder": "è¯·è¾“å…¥API Tokenï¼ˆæ”¯æŒå¤šä¸ªï¼Œç”¨é€—å·/æ¢è¡Œåˆ†éš”ï¼‰" if not saved_tokens else "ç•™ç©ºä½¿ç”¨å·²ä¿å­˜çš„Token",
                    "multiline": True
                }),
                "image_gen_mode": ("BOOLEAN", {
                    "default": False,
                    "label_on": "å›¾ç”Ÿå›¾æ¨¡å¼",
                    "label_off": "å›¾åƒç¼–è¾‘æ¨¡å¼"
                }),
            },
            "optional": {
                "gen_model": (gen_models, {
                    "default": gen_models[0] if gen_models else "Qwen/Qwen-Image"
                }),
                "edit_model": (edit_models, {
                    "default": edit_models[0] if edit_models else "Qwen/Qwen-Image-Edit"
                }),
                "negative_prompt": ("STRING", {
                    "multiline": True,
                    "default": ""
                }),
                "width": ("INT", {
                    "default": 512,
                    "min": 64,
                    "max": 1664,
                    "step": 8
                }),
                "height": ("INT", {
                    "default": 512,
                    "min": 64,
                    "max": 1664,
                    "step": 8
                }),
                "steps": ("INT", {
                    "default": 30,
                    "min": 1,
                    "max": 100,
                    "step": 1
                }),
                "guidance": ("FLOAT", {
                    "default": 3.5,
                    "min": 1.5,
                    "max": 20.0,
                    "step": 0.1
                }),
                "seed": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 2147483647
                }),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("edited_image",)
    FUNCTION = "edit_image"
    CATEGORY = "ModelScopeAPI"

    def edit_image(self, image, prompt, api_tokens, image_gen_mode=False, gen_model="Qwen/Qwen-Image", 
                   edit_model="Qwen/Qwen-Image-Edit", negative_prompt="", 
                   width=512, height=512, steps=30, guidance=3.5, seed=-1):
        config = load_config()
        tokens = parse_api_tokens(api_tokens)
        
        if not tokens:
            raise Exception("è¯·æä¾›è‡³å°‘ä¸€ä¸ªæœ‰æ•ˆçš„API Token")
        
        # ä¿å­˜Tokenï¼ˆå¦‚æœæä¾›äº†æ–°çš„ï¼‰
        if api_tokens and api_tokens.strip() not in ["", "***å·²ä¿å­˜{}ä¸ªToken***".format(len(load_api_tokens()))]:
            if save_api_tokens(tokens):
                print(f"âœ… å·²ä¿å­˜ {len(tokens)} ä¸ªAPI Token")
            else:
                print("âš ï¸ API Tokenä¿å­˜å¤±è´¥ï¼Œä½†ä¸å½±å“å½“å‰ä½¿ç”¨")
        
        # æ ¹æ®å¼€å…³é€‰æ‹©ä½¿ç”¨çš„æ¨¡å‹
        if image_gen_mode:
            model = gen_model
            mode_name = "å›¾ç”Ÿå›¾"
        else:
            model = edit_model
            mode_name = "å›¾åƒç¼–è¾‘"

        # è½®è¯¢å°è¯•æ¯ä¸ªToken
        last_exception = None
        for i, token in enumerate(tokens):
            try:
                print(f"ğŸ”„ å°è¯•ä½¿ç”¨ç¬¬ {i+1} ä¸ªAPI Token...")
                
                # å°†å›¾åƒè½¬æ¢ä¸ºä¸´æ—¶æ–‡ä»¶å¹¶ä¸Šä¼ è·å–URL
                temp_img_path = None
                image_url = None
                try:
                    # ä¿å­˜å›¾åƒåˆ°ä¸´æ—¶æ–‡ä»¶
                    temp_img_path = os.path.join(tempfile.gettempdir(), f"qwen_edit_temp_{int(time.time())}.jpg")
                    if len(image.shape) == 4:
                        img = image[0]
                    else:
                        img = image
                    
                    i = 255. * img.cpu().numpy()
                    img_pil = Image.fromarray(np.clip(i, 0, 255).astype(np.uint8))
                    img_pil.save(temp_img_path)
                    print(f"âœ… å›¾åƒå·²ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶: {temp_img_path}")
                    
                    # ä¸Šä¼ å›¾åƒåˆ°kefan.cnè·å–URL
                    upload_url = 'https://ai.kefan.cn/api/upload/local'
                    with open(temp_img_path, 'rb') as img_file:
                        files = {'file': img_file}
                        upload_response = requests.post(
                            upload_url,
                            files=files,
                            timeout=30
                        )
                        if upload_response.status_code == 200:
                            upload_data = upload_response.json()
                            if upload_data.get('success') == True and 'data' in upload_data:
                                image_url = upload_data['data']
                                print(f"âœ… å›¾åƒå·²ä¸Šä¼ æˆåŠŸï¼Œè·å–URL: {image_url}")
                            else:
                                print(f"âš ï¸ å›¾åƒä¸Šä¼ è¿”å›é”™è¯¯: {upload_response.text}")
                        else:
                            print(f"âš ï¸ å›¾åƒä¸Šä¼ å¤±è´¥: {upload_response.status_code}, {upload_response.text}")
                except Exception as e:
                    print(f"âš ï¸ å›¾åƒä¸Šä¼ å¼‚å¸¸: {str(e)}")
                
                # å¦‚æœä¸Šä¼ å¤±è´¥ï¼Œå›é€€åˆ°base64
                if not image_url:
                    print("âš ï¸ å›¾åƒURLè·å–å¤±è´¥ï¼Œå›é€€åˆ°ä½¿ç”¨base64")
                    image_data = tensor_to_base64_url(image)
                    payload = {
                        'model': model,
                        'prompt': prompt,
                        'image': image_data
                    }
                else:
                    payload = {
                        'model': model,
                        'prompt': prompt,
                        'image_url': image_url
                    }
                
                if negative_prompt.strip():
                    payload['negative_prompt'] = negative_prompt
                
                # æ·»åŠ æ–°å‚æ•°
                if width != 512 or height != 512:
                    size = f"{width}x{height}"
                    payload['size'] = size
                
                if steps != 30:
                    payload['steps'] = steps
                
                if guidance != 3.5:
                    payload['guidance'] = guidance
                
                if seed != -1:
                    payload['seed'] = seed
                
                headers = {
                    'Authorization': f'Bearer {token}',
                    'Content-Type': 'application/json',
                    'X-ModelScope-Async-Mode': 'true'
                }
                
                print(f"ğŸ–¼ï¸ å¼€å§‹{mode_name}...")
                print(f"âœï¸ ç¼–è¾‘æç¤º: {prompt}")
                print(f"ğŸ§  ä½¿ç”¨æ¨¡å‹: {model}")
                
                url = 'https://api-inference.modelscope.cn/v1/images/generations'
                submission_response = requests.post(
                    url,
                    data=json.dumps(payload, ensure_ascii=False).encode('utf-8'),
                    headers=headers,
                    timeout=config.get("timeout", 60)
                )
                
                if submission_response.status_code != 200:
                    raise Exception(f"APIè¯·æ±‚å¤±è´¥: {submission_response.status_code}, {submission_response.text}")
                
                submission_json = submission_response.json()
                result_image_url = None
                
                if 'task_id' in submission_json:
                    task_id = submission_json['task_id']
                    print(f"ğŸ•’ å·²æäº¤ä»»åŠ¡ï¼Œä»»åŠ¡ID: {task_id}ï¼Œå¼€å§‹è½®è¯¢...")
                    poll_start = time.time()
                    max_wait_seconds = max(60, config.get('timeout', 720))
                    
                    while True:
                        task_resp = requests.get(
                            f"https://api-inference.modelscope.cn/v1/tasks/{task_id}",
                            headers={
                                'Authorization': f'Bearer {token}',
                                'X-ModelScope-Task-Type': 'image_generation'
                            },
                            timeout=config.get("image_download_timeout", 120)
                        )
                        
                        if task_resp.status_code != 200:
                            raise Exception(f"ä»»åŠ¡æŸ¥è¯¢å¤±è´¥: {task_resp.status_code}, {task_resp.text}")
                        
                        task_data = task_resp.json()
                        status = task_data.get('task_status')
                        
                        if status == 'SUCCEED':
                            output_images = task_data.get('output_images') or []
                            if not output_images:
                                raise Exception("ä»»åŠ¡æˆåŠŸä½†æœªè¿”å›å›¾ç‰‡URL")
                            result_image_url = output_images[0]
                            print("âœ… ä»»åŠ¡å®Œæˆï¼Œå¼€å§‹ä¸‹è½½ç¼–è¾‘åçš„å›¾ç‰‡...")
                            break
                            
                        if status == 'FAILED':
                            error_message = task_data.get('errors', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                            error_code = task_data.get('errors', {}).get('code', 'æœªçŸ¥é”™è¯¯ç ')
                            raise Exception(f"ä»»åŠ¡å¤±è´¥: é”™è¯¯ç  {error_code}, é”™è¯¯ä¿¡æ¯: {error_message}")
                            
                        if time.time() - poll_start > max_wait_seconds:
                            raise Exception("ä»»åŠ¡è½®è¯¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•æˆ–é™ä½å¹¶å‘")
                            
                        time.sleep(5)
                else:
                    raise Exception(f"æœªè¯†åˆ«çš„APIè¿”å›æ ¼å¼: {submission_json}")
                
                img_response = requests.get(result_image_url, timeout=config.get("image_download_timeout", 30))
                if img_response.status_code != 200:
                    raise Exception(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_response.status_code}")
                
                pil_image = Image.open(BytesIO(img_response.content))
                if pil_image.mode != 'RGB':
                    pil_image = pil_image.convert('RGB')
                
                image_np = np.array(pil_image).astype(np.float32) / 255.0
                image_tensor = torch.from_numpy(image_np)[None,]
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if temp_img_path and os.path.exists(temp_img_path):
                    try:
                        os.remove(temp_img_path)
                    except:
                        pass
                
                print(f"ğŸ‰ {mode_name}å®Œæˆï¼ä½¿ç”¨çš„ç¬¬ {i+1} ä¸ªAPI Token")
                return (image_tensor,)
                
            except Exception as e:
                last_exception = e
                print(f"âš ï¸ ç¬¬ {i+1} ä¸ªAPI Tokenå¤±è´¥: {str(e)}")
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if temp_img_path and os.path.exists(temp_img_path):
                    try:
                        os.remove(temp_img_path)
                    except:
                        pass
                if i < len(tokens) - 1:  # ä¸æ˜¯æœ€åä¸€ä¸ªToken
                    print(f"â¡ï¸ å°è¯•ä¸‹ä¸€ä¸ªAPI Token...")
                    continue
                else:
                    break  # æ‰€æœ‰Tokenéƒ½å¤±è´¥äº†
        
        # æ‰€æœ‰Tokenéƒ½å¤±è´¥
        raise Exception(f"æ‰€æœ‰ {len(tokens)} ä¸ªAPI Tokenéƒ½å¤±è´¥äº†ã€‚æœ€åçš„é”™è¯¯: {str(last_exception)}")


# èŠ‚ç‚¹æ˜ å°„
NODE_CLASS_MAPPINGS = {
    "ModelScopeImageNode": ModelScopeImageNode,
    "ModelScopeImageEditNode": ModelScopeImageEditNode
}
 
NODE_DISPLAY_NAME_MAPPINGS = {
    "ModelScopeImageNode": "ModelScope-Image ç”Ÿå›¾èŠ‚ç‚¹",
    "ModelScopeImageEditNode": "ModelScope-Image å›¾åƒç¼–è¾‘èŠ‚ç‚¹"
}

import requests
import json
import time
import torch
import numpy as np
from PIL import Image
from io import BytesIO
import os
import folder_paths
import base64
import tempfile
import re

# -------------------------- æ ¸å¿ƒé…ç½®ç®¡ç† --------------------------
def load_config():
    """ä»modelscope_config.jsonåŠ è½½é…ç½®ï¼Œç¡®ä¿ä¼˜å…ˆä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„lora_presets"""
    config_path = os.path.join(os.path.dirname(__file__), 'modelscope_config.json')
    default_config = {
        "default_model": "Qwen/Qwen-Image",
        "timeout": 720,
        "image_download_timeout": 30,
        "default_prompt": "A beautiful landscape",
        "default_negative_prompt": "",
        "default_width": 512,
        "default_height": 512,
        "default_seed": -1,
        "default_steps": 30,
        "default_guidance": 7.5,
        "default_lora_weight": 0.8,
        "image_models": ["Qwen/Qwen-Image"],
        "image_edit_models": ["Qwen/Qwen-Image-Edit"],
        "lora_presets": [
            {"name": "æ— LoRA", "model_id": "", "weight": 0.8}
        ],
        "api_tokens": []
    }
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
            # ç¡®ä¿é…ç½®æ–‡ä»¶ä¸­å­˜åœ¨æ‰€æœ‰å¿…è¦å­—æ®µï¼Œç¼ºå¤±åˆ™è¡¥å……åˆ™è¡¥å……é»˜è®¤å€¼
            for key, value in default_config.items():
                if key not in config:
                    config[key] = value
            return config
    except Exception as e:
        print(f"è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
        return default_config

def save_config(config: dict) -> bool:
    """ä¿å­˜é…ç½®åˆ°modelscope_config.json"""
    config_path = os.path.join(os.path.dirname(__file__), 'modelscope_config.json')
    try:
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"ä¿å­˜é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return False

# -------------------------- API Tokenç®¡ç† --------------------------
def save_api_tokens(tokens):
    try:
        cfg = load_config()
        cfg["api_tokens"] = tokens
        return save_config(cfg)
    except Exception as e:
        print(f"ä¿å­˜API tokenså¤±è´¥: {e}")
        return False

def load_api_tokens():
    try:
        cfg = load_config()
        tokens_from_cfg = cfg.get("api_tokens", [])
        if tokens_from_cfg and isinstance(tokens_from_cfg, list):
            return [token.strip() for token in tokens_from_cfg if token.strip()]
        return []
    except Exception as e:
        print(f"åŠ è½½API tokenså¤±è´¥: {e}")
        return []

def parse_api_tokens(token_input):
    if not token_input or token_input.strip() in ["", "***å·²ä¿å­˜***"]:
        return load_api_tokens()
    
    tokens = re.split(r'[,;\n]+', token_input)
    return [token.strip() for token in tokens if token.strip()]

# -------------------------- å›¾åƒè½¬æ¢å·¥å…· --------------------------
def tensor_to_base64_url(image_tensor):
    try:
        if len(image_tensor.shape) == 4:
            image_tensor = image_tensor.squeeze(0)
        
        if image_tensor.max() <= 1.0:
            image_np = (image_tensor.cpu().numpy() * 255).astype(np.uint8)
        else:
            image_np = image_tensor.cpu().numpy().astype(np.uint8)
        
        pil_image = Image.fromarray(image_np)
        buffer = BytesIO()
        pil_image.save(buffer, format='JPEG', quality=85)
        img_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
        
        return f"data:image/jpeg;base64,{img_base64}"
        
    except Exception as e:
        raise Exception(f"å›¾åƒæ ¼å¼è½¬æ¢å¤±è´¥: {str(e)}")

# -------------------------- LoRAé¢„è®¾ç®¡ç†èŠ‚ç‚¹ --------------------------
class ModelScopeLoraPresetNode:
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        # ä»é…ç½®æ–‡ä»¶åŠ è½½LoRAé¢„è®¾åˆ—è¡¨
        config = load_config()
        lora_presets = config.get("lora_presets", [])
        preset_names = [preset.get("name", "æ— LoRA") for preset in lora_presets]
        
        return {
            "required": {
                "action": (["æŸ¥çœ‹é¢„è®¾", "æ·»åŠ é¢„è®¾", "åˆ é™¤é¢„è®¾", "ä¿å­˜é¢„è®¾"], {"default": "æŸ¥çœ‹é¢„è®¾"}),
            },
            "optional": {
                "preset_name": ("STRING", {"default": "è‡ªå®šä¹‰LoRA", "label": "é¢„è®¾åç§°"}),
                "lora_model_id": ("STRING", {"default": "", "label": "LoRAæ¨¡å‹ID", "placeholder": "ä¾‹å¦‚ï¼šqiyuanai/TikTok_Xiaohongshu_career_line_beauty_v1"}),
                "default_weight": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.1, "label": "é»˜è®¤æƒé‡"}),
                "target_preset": (preset_names, {"default": preset_names[0] if preset_names else "æ— LoRA", "label": "ç›®æ ‡é¢„è®¾"}),
            }
        }
    
    RETURN_TYPES = ("STRING", "FLOAT", "STRING")
    RETURN_NAMES = ("lora_model_id", "lora_weight", "preset_info")
    FUNCTION = "manage_lora_presets"
    CATEGORY = "ModelScopeAPI/LoRA"
    
    def manage_lora_presets(self, action, preset_name="", lora_model_id="", default_weight=0.8, target_preset=""):
        # æ‰€æœ‰æ“ä½œå‡åŸºäºé…ç½®æ–‡ä»¶ä¸­çš„LoRAé¢„è®¾
        config = load_config()
        lora_presets = config.get("lora_presets", [])
        preset_info = f"å½“å‰å…±æœ‰ {len(lora_presets)} ä¸ªLoRAé¢„è®¾"
        
        if action == "æŸ¥çœ‹é¢„è®¾":
            info_lines = ["=== LoRAé¢„è®¾åˆ—è¡¨ ==="]
            for i, preset in enumerate(lora_presets):
                info_lines.append(f"{i+1}. {preset.get('name')} | ID: {preset.get('model_id')} | æƒé‡: {preset.get('weight')}")
            preset_info = "\n".join(info_lines)
            selected_preset = next((p for p in lora_presets if p.get("name") == target_preset), {"model_id": "", "weight": 0.8})
            return (selected_preset.get("model_id"), selected_preset.get("weight"), preset_info)
        
        elif action == "æ·»åŠ é¢„è®¾":
            if not preset_name or preset_name.strip() == "":
                raise Exception("é¢„è®¾åç§°ä¸èƒ½ä¸ºç©º")
            
            if any(p.get("name") == preset_name for p in lora_presets):
                raise Exception(f"å·²å­˜åœ¨åä¸º {preset_name} çš„é¢„è®¾")
            
            new_preset = {
                "name": preset_name.strip(),
                "model_id": lora_model_id.strip(),
                "weight": float(default_weight)
            }
            lora_presets.append(new_preset)
            config["lora_presets"] = lora_presets
            save_config(config)
            preset_info = f"æˆåŠŸæ·»åŠ é¢„è®¾: {preset_name} | ID: {lora_model_id}"
            return (lora_model_id, default_weight, preset_info)
        
        elif action == "åˆ é™¤é¢„è®¾":
            if target_preset == "æ— LoRA":
                raise Exception("ä¸èƒ½åˆ é™¤é»˜è®¤çš„æ— LoRAé¢„è®¾")
            
            original_count = len(lora_presets)
            lora_presets = [p for p in lora_presets if p.get("name") != target_preset]
            if len(lora_presets) == original_count:
                raise Exception(f"æœªæ‰¾åˆ°é¢„è®¾: {target_preset}")
            
            config["lora_presets"] = lora_presets
            save_config(config)
            preset_info = f"æˆåŠŸåˆ é™¤é¢„è®¾: {target_preset}"
            return ("", 0.8, preset_info)
        
        elif action == "ä¿å­˜é¢„è®¾":
            updated = False
            for i, preset in enumerate(lora_presets):
                if preset.get("name") == target_preset:
                    lora_presets[i]["model_id"] = lora_model_id.strip()
                    lora_presets[i]["weight"] = float(default_weight)
                    updated = True
                    break
            
            if not updated:
                raise Exception(f"æœªæ‰¾åˆ°é¢„è®¾: {target_preset}")
            
            config["lora_presets"] = lora_presets
            save_config(config)
            preset_info = f"æˆåŠŸæ›´æ–°é¢„è®¾: {target_preset} | æ–°ID: {lora_model_id} | æ–°æƒé‡: {default_weight}"
            return (lora_model_id, default_weight, preset_info)
        
        return ("", 0.8, preset_info)

# -------------------------- å•LoRAåŠ è½½èŠ‚ç‚¹ --------------------------
class ModelScopeSingleLoraLoaderNode:
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        # ä»é…ç½®æ–‡ä»¶åŠ è½½LoRAé¢„è®¾é€‰é¡¹
        config = load_config()
        lora_presets = config.get("lora_presets", [])
        preset_options = [preset.get("name", "æ— LoRA") for preset in lora_presets]
        
        return {
            "required": {
                "lora_preset": (preset_options, {"default": preset_options[0], "label": "LoRAé¢„è®¾"}),
            },
            "optional": {
                "lora_weight": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.1, "label": "è‡ªå®šä¹‰æƒé‡"}),
                "use_custom_weight": ("BOOLEAN", {"default": False, "label_on": "ä½¿ç”¨è‡ªå®šä¹‰æƒé‡", "label_off": "ä½¿ç”¨é¢„è®¾æƒé‡"}),
            }
        }
    
    RETURN_TYPES = ("STRING", "FLOAT")
    RETURN_NAMES = ("lora_id", "lora_weight")
    FUNCTION = "load_single_lora"
    CATEGORY = "ModelScopeAPI/LoRA"
    
    def load_single_lora(self, lora_preset, lora_weight=0.8, use_custom_weight=False):
        # ä»é…ç½®æ–‡ä»¶è¯»å–é€‰ä¸­çš„LoRAä¿¡æ¯
        config = load_config()
        lora_presets = config.get("lora_presets", [])
        
        selected_preset = next((p for p in lora_presets if p.get("name") == lora_preset), {"model_id": "", "weight": 0.8})
        lora_id = selected_preset.get("model_id", "")
        final_weight = lora_weight if use_custom_weight else selected_preset.get("weight", 0.8)
        
        return (lora_id, final_weight)

# -------------------------- å¤šLoRAåŠ è½½èŠ‚ç‚¹ --------------------------
class ModelScopeMultiLoraLoaderNode:
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        # ä»é…ç½®æ–‡ä»¶åŠ è½½LoRAé¢„è®¾é€‰é¡¹
        config = load_config()
        lora_presets = config.get("lora_presets", [])
        preset_options = [preset.get("name", "æ— LoRA") for preset in lora_presets]
        
        return {
            "required": {
                "lora1_preset": (preset_options, {"default": preset_options[0], "label": "LoRA 1 é¢„è®¾"}),
                "lora2_preset": (preset_options, {"default": preset_options[0], "label": "LoRA 2 é¢„è®¾"}),
                "lora3_preset": (preset_options, {"default": preset_options[0], "label": "LoRA 3 é¢„è®¾"}),
            },
            "optional": {
                "lora1_weight": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.1, "label": "LoRA 1 æƒé‡"}),
                "lora2_weight": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.1, "label": "LoRA 2 æƒé‡"}),
                "lora3_weight": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.1, "label": "LoRA 3 æƒé‡"}),
                "lora1_use_custom": ("BOOLEAN", {"default": False, "label_on": "LoRA1ç”¨è‡ªå®šä¹‰æƒé‡", "label_off": "ç”¨é¢„è®¾æƒé‡"}),
                "lora2_use_custom": ("BOOLEAN", {"default": False, "label_on": "LoRA2ç”¨è‡ªå®šä¹‰æƒé‡", "label_off": "ç”¨é¢„è®¾æƒé‡"}),
                "lora3_use_custom": ("BOOLEAN", {"default": False, "label_on": "LoRA3ç”¨è‡ªå®šä¹‰æƒé‡", "label_off": "ç”¨é¢„è®¾æƒé‡"}),
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING", "STRING", "FLOAT", "FLOAT", "FLOAT")
    RETURN_NAMES = ("lora1_id", "lora2_id", "lora3_id", "lora1_w", "lora2_w", "lora3_w")
    FUNCTION = "load_multi_lora"
    CATEGORY = "ModelScopeAPI/LoRA"
    
    def load_multi_lora(self, lora1_preset, lora2_preset, lora3_preset,
                        lora1_weight=0.8, lora2_weight=0.8, lora3_weight=0.8,
                        lora1_use_custom=False, lora2_use_custom=False, lora3_use_custom=False):
        # ä»é…ç½®æ–‡ä»¶è¯»å–å¤šä¸ªLoRAä¿¡æ¯
        config = load_config()
        lora_presets = config.get("lora_presets", [])
        
        def get_lora_info(preset_name, custom_weight, use_custom):
            preset = next((p for p in lora_presets if p.get("name") == preset_name), {"model_id": "", "weight": 0.8})
            model_id = preset.get("model_id", "")
            final_weight = custom_weight if use_custom else preset.get("weight", 0.8)
            return model_id, final_weight
        
        lora1_id, lora1_w = get_lora_info(lora1_preset, lora1_weight, lora1_use_custom)
        lora2_id, lora2_w = get_lora_info(lora2_preset, lora2_weight, lora2_use_custom)
        lora3_id, lora3_w = get_lora_info(lora3_preset, lora3_weight, lora3_use_custom)
        
        return (lora1_id, lora2_id, lora3_id, lora1_w, lora2_w, lora3_w)

# -------------------------- ç”Ÿå›¾èŠ‚ç‚¹ --------------------------
class ModelScopeImageNode:
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        config = load_config()
        saved_tokens = load_api_tokens()
        
        return {
            "required": {
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": config.get("default_prompt", "A beautiful landscape")
                }),
                "api_tokens": ("STRING", {
                    "default": "***å·²ä¿å­˜{}ä¸ªToken***".format(len(saved_tokens)) if saved_tokens else "",
                    "placeholder": "è¯·è¾“å…¥API Tokenï¼ˆæ”¯æŒå¤šä¸ªï¼Œç”¨é€—å·/æ¢è¡Œåˆ†éš”ï¼‰" if not saved_tokens else "ç•™ç©ºä½¿ç”¨å·²ä¿å­˜çš„Token",
                    "multiline": True
                }),
            },
            "optional": {
                "model": (config.get("image_models", ["Qwen/Qwen-Image"]), {
                    "default": config.get("default_model", "Qwen/Qwen-Image")
                }),
                "negative_prompt": ("STRING", {
                    "multiline": True,
                    "default": config.get("default_negative_prompt", "")
                }),
                "width": ("INT", {
                    "default": config.get("default_width", 512),
                    "min": 64,
                    "max": 2048,
                    "step": 64
                }),
                "height": ("INT", {
                    "default": config.get("default_height", 512),
                    "min": 64,
                    "max": 2048,
                    "step": 64
                }),
                "seed": ("INT", {
                    "default": config.get("default_seed", -1),
                    "min": -1,
                    "max": 2147483647
                }),
                "steps": ("INT", {
                    "default": config.get("default_steps", 30),
                    "min": 1,
                    "max": 100
                }),
                "guidance": ("FLOAT", {
                    "default": config.get("default_guidance", 7.5),
                    "min": 1.5,
                    "max": 20.0,
                    "step": 0.1
                }),
                "lora1_id": ("STRING", {"default": "", "label": "LoRA1 æ¨¡å‹ID"}),
                "lora1_w": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.1, "label": "LoRA1 æƒé‡"}),
                "lora2_id": ("STRING", {"default": "", "label": "LoRA2 æ¨¡å‹ID"}),
                "lora2_w": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.1, "label": "LoRA2 æƒé‡"}),
                "lora3_id": ("STRING", {"default": "", "label": "LoRA3 æ¨¡å‹ID"}),
                "lora3_w": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.1, "label": "LoRA3 æƒé‡"}),
            }
        }
    
    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("image",)
    FUNCTION = "generate_image"
    CATEGORY = "ModelScopeAPI"
    
    def generate_image(self, prompt, api_tokens, model="Qwen/Qwen-Image", negative_prompt="", width=512, height=512, seed=-1, steps=30, guidance=7.5,
                       lora1_id="", lora1_w=0.8, lora2_id="", lora2_w=0.8, lora3_id="", lora3_w=0.8):
        config = load_config()
        tokens = parse_api_tokens(api_tokens)
        
        if not tokens:
            raise Exception("è¯·æä¾›è‡³å°‘ä¸€ä¸ªæœ‰æ•ˆçš„API Token")
        
        # ä¿å­˜æ–°Tokenï¼ˆå¦‚æœæœ‰å˜åŒ–ï¼‰
        if api_tokens and api_tokens.strip() not in ["", "***å·²ä¿å­˜{}ä¸ªToken***".format(len(load_api_tokens()))]:
            if save_api_tokens(tokens):
                print(f"âœ… å·²ä¿å­˜ {len(tokens)} ä¸ªAPI Token")
            else:
                print("âš ï¸ API Tokenä¿å­˜å¤±è´¥ï¼Œä½†ä¸å½±å“å½“å‰ä½¿ç”¨")
        
        print(f"ğŸ” å¼€å§‹ç”Ÿæˆå›¾åƒ...")
        print(f"ğŸ“ æç¤ºè¯: {prompt}")
        print(f"âŒ åå‘æç¤ºè¯: {negative_prompt if negative_prompt else 'æ— '}")
        print(f"ğŸ¤– æ¨¡å‹: {model}")
        print(f"ğŸ”‘ å¯ç”¨Tokenæ•°é‡: {len(tokens)}")
        print(f"ğŸ“ å°ºå¯¸: {width}x{height}")
        print(f"ğŸ”„ æ­¥æ•°: {steps}")
        print(f"ğŸ§­ å¼•å¯¼ç³»æ•°: {guidance}")
        print(f"ğŸ”¢ ç§å­: {seed if seed != -1 else 'éšæœº'}")
        
        # æ‰“å°LoRAä¿¡æ¯
        lora_info = []
        if lora1_id.strip():
            lora_info.append(f"LoRA1: {lora1_id} (æƒé‡: {lora1_w})")
        if lora2_id.strip():
            lora_info.append(f"LoRA2: {lora2_id} (æƒé‡: {lora2_w})")
        if lora3_id.strip():
            lora_info.append(f"LoRA3: {lora3_id} (æƒé‡: {lora3_w})")
        if lora_info:
            print(f"ğŸ”§ LoRAé…ç½®: {', '.join(lora_info)}")
        else:
            print("ğŸ”§ æœªä½¿ç”¨LoRA")
        
        last_exception = None
        for i, token in enumerate(tokens):
            try:
                print(f"ğŸ”„ å°è¯•ä½¿ç”¨ç¬¬ {i+1}/{len(tokens)} ä¸ªToken...")
                
                url = 'https://api-inference.modelscope.cn/v1/images/generations'
                payload = {
                    'model': model,
                    'prompt': prompt,
                    'size': f"{width}x{height}",
                    'steps': steps,
                    'guidance': guidance
                }
                
                lora_dict = {}
                if lora1_id and lora1_id.strip() != "":
                    lora_dict[lora1_id.strip()] = float(lora1_w)
                if lora2_id and lora2_id.strip() != "":
                    lora_dict[lora2_id.strip()] = float(lora2_w)
                if lora3_id and lora3_id.strip() != "":
                    lora_dict[lora3_id.strip()] = float(lora3_w)
                
                if lora_dict:
                    payload['loras'] = lora_dict
                    first_lora_id = next(iter(lora_dict.keys()))
                    first_lora_w = next(iter(lora_dict.values()))
                    payload['lora'] = first_lora_id
                    payload['lora_weight'] = first_lora_w
                
                if negative_prompt.strip():
                    payload['negative_prompt'] = negative_prompt
                if seed != -1:
                    payload['seed'] = seed
                else:
                    import random
                    payload['seed'] = random.randint(0, 2147483647)
                    print(f"ğŸ² éšæœºç”Ÿæˆç§å­: {payload['seed']}")
                
                headers = {
                    'Authorization': f'Bearer {token}',
                    'Content-Type': 'application/json',
                    'X-ModelScope-Async-Mode': 'true',
                    'X-ModelScope-Task-Type': 'text-to-image-generation',
                    'X-ModelScope-Request-Params': json.dumps({'loras': lora_dict} if lora_dict else {})
                }
                
                print(f"ğŸš€ å‘é€APIè¯·æ±‚åˆ° {model}...")
                submission_response = requests.post(
                    url, 
                    data=json.dumps(payload, ensure_ascii=False).encode('utf-8'), 
                    headers=headers,
                    timeout=config.get("timeout", 60)
                )
                
                if submission_response.status_code == 400:
                    print("âš ï¸ æ ‡å‡†è¯·æ±‚å‚æ•°å¤±è´¥ï¼Œå°è¯•ç®€åŒ–å‚æ•°...")
                    minimal_payload = {
                        'model': model,
                        'prompt': prompt
                    }
                    if lora_dict:
                        minimal_payload['loras'] = lora_dict
                        minimal_payload['lora'] = first_lora_id
                        minimal_payload['lora_weight'] = first_lora_w
                    
                    submission_response = requests.post(
                        url,
                        data=json.dumps(minimal_payload, ensure_ascii=False).encode('utf-8'),
                        headers=headers,
                        timeout=config.get("timeout", 60)
                    )
                
                if submission_response.status_code != 200:
                    raise Exception(f"APIè¯·æ±‚å¤±è´¥: {submission_response.status_code}, {submission_response.text}")
                
                submission_json = submission_response.json()
                image_url = None
                
                if 'task_id' in submission_json:
                    task_id = submission_json['task_id']
                    print(f"ğŸ“Œ è·å–ä»»åŠ¡ID: {task_id}, å¼€å§‹è½®è¯¢ç»“æœ...")
                    poll_start = time.time()
                    max_wait_seconds = max(60, config.get('timeout', 720))
                    while True:
                        task_resp = requests.get(
                            f"https://api-inference.modelscope.cn/v1/tasks/{task_id}",
                            headers={
                                'Authorization': f'Bearer {token}',
                                'X-ModelScope-Task-Type': 'image_generation'
                            },
                            timeout=config.get("image_download_timeout", 120)
                        )
                        
                        if task_resp.status_code != 200:
                            raise Exception(f"ä»»åŠ¡æŸ¥è¯¢å¤±è´¥: {task_resp.status_code}, {task_resp.text}")
                        
                        task_data = task_resp.json()
                        status = task_data.get('task_status')
                        print(f"âŒ› ä»»åŠ¡çŠ¶æ€: {status} (å·²ç­‰å¾… {int(time.time() - poll_start)} ç§’)")
                        
                        if status == 'SUCCEED':
                            output_images = task_data.get('output_images') or []
                            if not output_images:
                                raise Exception("ä»»åŠ¡æˆåŠŸä½†æœªè¿”å›å›¾ç‰‡URL")
                            image_url = output_images[0]
                            print(f"âœ… ä»»åŠ¡å®Œæˆï¼Œè·å–å›¾ç‰‡URL")
                            break
                        if status == 'FAILED':
                            raise Exception(f"ä»»åŠ¡å¤±è´¥: {task_data}")
                        if time.time() - poll_start > max_wait_seconds:
                            raise Exception(f"ä»»åŠ¡è½®è¯¢è¶…æ—¶ ({max_wait_seconds}ç§’)ï¼Œè¯·ç¨åé‡è¯•æˆ–é™ä½å¹¶å‘")
                        time.sleep(5)
                elif 'images' in submission_json and len(submission_json['images']) > 0:
                    image_url = submission_json['images'][0]['url']
                    print(f"âœ… ç›´æ¥è·å–å›¾ç‰‡URL")
                else:
                    raise Exception(f"æœªè¯†åˆ«çš„APIè¿”å›æ ¼å¼: {submission_json}")
                
                print(f"ğŸ“¥ ä¸‹è½½å›¾ç‰‡...")
                img_response = requests.get(image_url, timeout=config.get("image_download_timeout", 30))
                if img_response.status_code != 200:
                    raise Exception(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_response.status_code}")
                
                print(f"ğŸ–¼ï¸ å¤„ç†å›¾ç‰‡æ•°æ®...")
                pil_image = Image.open(BytesIO(img_response.content))
                if pil_image.mode != 'RGB':
                    pil_image = pil_image.convert('RGB')
                image_np = np.array(pil_image).astype(np.float32) / 255.0
                image_tensor = torch.from_numpy(image_np)[None,]
                
                print(f"âœ… ç¬¬ {i+1} ä¸ªTokenè°ƒç”¨æˆåŠŸï¼Œå›¾åƒç”Ÿæˆå®Œæˆ!")
                return (image_tensor,)
                
            except Exception as e:
                last_exception = e
                print(f"âŒ ç¬¬ {i+1} ä¸ªTokenè°ƒç”¨å¤±è´¥: {str(e)}")
                if i < len(tokens) - 1:
                    print(f"â³ å‡†å¤‡å°è¯•ä¸‹ä¸€ä¸ªToken...")
                    continue
                else:
                    break
        
        raise Exception(f"æ‰€æœ‰ {len(tokens)} ä¸ªAPI Tokenéƒ½å¤±è´¥äº†ã€‚æœ€åçš„é”™è¯¯: {str(last_exception)}")

# -------------------------- ç¼–è¾‘èŠ‚ç‚¹ï¼ˆå·²æ·»åŠ LoRAåŠŸèƒ½ï¼‰ --------------------------
class ModelScopeImageEditNode:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        config = load_config()
        saved_tokens = load_api_tokens()
        
        edit_models = config.get("image_edit_models", ["Qwen/Qwen-Image-Edit"])
        gen_models = config.get("image_models", ["Qwen/Qwen-Image"])

        return {
            "required": {
                "image": ("IMAGE",),
                "prompt": ("STRING", {
                    "multiline": True,
                    "default": "ä¿®æ”¹å›¾ç‰‡ä¸­çš„å†…å®¹"
                }),
                "api_tokens": ("STRING", {
                    "default": "***å·²ä¿å­˜{}ä¸ªToken***".format(len(saved_tokens)) if saved_tokens else "",
                    "placeholder": "è¯·è¾“å…¥API Tokenï¼ˆæ”¯æŒå¤šä¸ªï¼Œç”¨é€—å·/æ¢è¡Œåˆ†éš”ï¼‰" if not saved_tokens else "ç•™ç©ºä½¿ç”¨å·²ä¿å­˜çš„Token",
                    "multiline": True
                }),
                "image_gen_mode": ("BOOLEAN", {
                    "default": False,
                    "label_on": "å›¾ç”Ÿå›¾æ¨¡å¼",
                    "label_off": "å›¾åƒç¼–è¾‘æ¨¡å¼"
                }),
            },
            "optional": {
                "gen_model": (gen_models, {
                    "default": gen_models[0] if gen_models else "Qwen/Qwen-Image"
                }),
                "edit_model": (edit_models, {
                    "default": edit_models[0] if edit_models else "Qwen/Qwen-Image-Edit"
                }),
                "negative_prompt": ("STRING", {
                    "multiline": True,
                    "default": ""
                }),
                "width": ("INT", {
                    "default": 512,
                    "min": 64,
                    "max": 1664,
                    "step": 8
                }),
                "height": ("INT", {
                    "default": 512,
                    "min": 64,
                    "max": 1664,
                    "step": 8
                }),
                "steps": ("INT", {
                    "default": 30,
                    "min": 1,
                    "max": 100,
                    "step": 1
                }),
                "guidance": ("FLOAT", {
                    "default": 3.5,
                    "min": 1.5,
                    "max": 20.0,
                    "step": 0.1
                }),
                "seed": ("INT", {
                    "default": -1,
                    "min": -1,
                    "max": 2147483647
                }),
                # LoRAç›¸å…³å‚æ•°ï¼ˆä¸ç”Ÿå›¾èŠ‚ç‚¹ä¿æŒä¸€è‡´ï¼‰
                "lora1_id": ("STRING", {"default": "", "label": "LoRA1 æ¨¡å‹ID"}),
                "lora1_w": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.1, "label": "LoRA1 æƒé‡"}),
                "lora2_id": ("STRING", {"default": "", "label": "LoRA2 æ¨¡å‹ID"}),
                "lora2_w": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.1, "label": "LoRA2 æƒé‡"}),
                "lora3_id": ("STRING", {"default": "", "label": "LoRA3 æ¨¡å‹ID"}),
                "lora3_w": ("FLOAT", {"default": 0.8, "min": 0.0, "max": 2.0, "step": 0.1, "label": "LoRA3 æƒé‡"}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("edited_image",)
    FUNCTION = "edit_image"
    CATEGORY = "ModelScopeAPI"

    def edit_image(self, image, prompt, api_tokens, image_gen_mode=False, gen_model="Qwen/Qwen-Image", 
                   edit_model="Qwen/Qwen-Image-Edit", negative_prompt="", 
                   width=512, height=512, steps=30, guidance=3.5, seed=-1,
                   lora1_id="", lora1_w=0.8, lora2_id="", lora2_w=0.8, lora3_id="", lora3_w=0.8):
        config = load_config()
        tokens = parse_api_tokens(api_tokens)
        
        if not tokens:
            raise Exception("è¯·æä¾›è‡³å°‘ä¸€ä¸ªæœ‰æ•ˆçš„API Token")
        
        # ä¿å­˜æ–°Tokenï¼ˆå¦‚æœæœ‰å˜åŒ–ï¼‰
        if api_tokens and api_tokens.strip() not in ["", "***å·²ä¿å­˜{}ä¸ªToken***".format(len(load_api_tokens()))]:
            if save_api_tokens(tokens):
                print(f"âœ… å·²ä¿å­˜ {len(tokens)} ä¸ªAPI Token")
            else:
                print("âš ï¸ API Tokenä¿å­˜å¤±è´¥ï¼Œä½†ä¸å½±å“å½“å‰ä½¿ç”¨")
        
        mode = "å›¾ç”Ÿå›¾æ¨¡å¼" if image_gen_mode else "å›¾åƒç¼–è¾‘æ¨¡å¼"
        model = gen_model if image_gen_mode else edit_model
        
        print(f"ğŸ” å¼€å§‹å›¾åƒç¼–è¾‘...")
        print(f"ğŸ“ æç¤ºè¯: {prompt}")
        print(f"âŒ åå‘æç¤ºè¯: {negative_prompt if negative_prompt else 'æ— '}")
        print(f"ğŸ¤– æ¨¡å‹: {model} ({mode})")
        print(f"ğŸ”‘ å¯ç”¨Tokenæ•°é‡: {len(tokens)}")
        print(f"ğŸ“ å°ºå¯¸: {width}x{height}")
        print(f"ğŸ”„ æ­¥æ•°: {steps}")
        print(f"ğŸ§­ å¼•å¯¼ç³»æ•°: {guidance}")
        print(f"ğŸ”¢ ç§å­: {seed if seed != -1 else 'éšæœº'}")
        
        # æ‰“å°LoRAä¿¡æ¯
        lora_info = []
        if lora1_id.strip():
            lora_info.append(f"LoRA1: {lora1_id} (æƒé‡: {lora1_w})")
        if lora2_id.strip():
            lora_info.append(f"LoRA2: {lora2_id} (æƒé‡: {lora2_w})")
        if lora3_id.strip():
            lora_info.append(f"LoRA3: {lora3_id} (æƒé‡: {lora3_w})")
        if lora_info:
            print(f"ğŸ”§ LoRAé…ç½®: {', '.join(lora_info)}")
        else:
            print("ğŸ”§ æœªä½¿ç”¨LoRA")

        last_exception = None
        for i, token in enumerate(tokens):
            try:
                print(f"ğŸ”„ å°è¯•ä½¿ç”¨ç¬¬ {i+1}/{len(tokens)} ä¸ªToken...")
                
                temp_img_path = None
                image_url = None
                try:
                    # ä¿å­˜ä¸´æ—¶å›¾åƒå¹¶ä¸Šä¼ 
                    temp_img_path = os.path.join(tempfile.gettempdir(), f"qwen_edit_temp_{int(time.time())}.jpg")
                    if len(image.shape) == 4:
                        img = image[0]
                    else:
                        img = image
                    
                    img_np = 255. * img.cpu().numpy()
                    img_pil = Image.fromarray(np.clip(img_np, 0, 255).astype(np.uint8))
                    img_pil.save(temp_img_path)
                    print(f"ğŸ’¾ å·²ä¿å­˜ä¸´æ—¶å›¾åƒåˆ° {temp_img_path}")
                    
                    # ä¸Šä¼ å›¾åƒ
                    upload_url = 'https://ai.kefan.cn/api/upload/local'
                    with open(temp_img_path, 'rb') as img_file:
                        files = {'file': img_file}
                        upload_response = requests.post(
                            upload_url,
                            files=files,
                            timeout=30
                        )
                        if upload_response.status_code == 200:
                            upload_data = upload_response.json()
                            if upload_data.get('success') == True and 'data' in upload_data:
                                image_url = upload_data['data']
                                print(f"ğŸ“¤ å›¾åƒä¸Šä¼ æˆåŠŸï¼ŒURL: {image_url[:50]}...")
                except Exception as e:
                    print(f"âš ï¸ å›¾åƒä¸Šä¼ å¤±è´¥ï¼Œå°†ä½¿ç”¨base64ç¼–ç : {str(e)}")
                
                # æ„å»ºè¯·æ±‚ payload
                if not image_url:
                    print("ğŸ”„ è½¬æ¢å›¾åƒä¸ºbase64æ ¼å¼...")
                    image_data = tensor_to_base64_url(image)
                    payload = {
                        'model': model,
                        'prompt': prompt,
                        'image': image_data
                    }
                else:
                    payload = {
                        'model': model,
                        'prompt': prompt,
                        'image_url': image_url
                    }
                
                # æ„å»ºLoRAå‚æ•°
                lora_dict = {}
                if lora1_id and lora1_id.strip() != "":
                    lora_dict[lora1_id.strip()] = float(lora1_w)
                if lora2_id and lora2_id.strip() != "":
                    lora_dict[lora2_id.strip()] = float(lora2_w)
                if lora3_id and lora3_id.strip() != "":
                    lora_dict[lora3_id.strip()] = float(lora3_w)
                
                if lora_dict:
                    payload['loras'] = lora_dict
                    first_lora_id = next(iter(lora_dict.keys()))
                    first_lora_w = next(iter(lora_dict.values()))
                    payload['lora'] = first_lora_id
                    payload['lora_weight'] = first_lora_w
                
                # æ·»åŠ å…¶ä»–å‚æ•°
                if negative_prompt.strip():
                    payload['negative_prompt'] = negative_prompt
                if width != 512 or height != 512:
                    payload['size'] = f"{width}x{height}"
                if steps != 30:
                    payload['steps'] = steps
                if guidance != 3.5:
                    payload['guidance'] = guidance
                if seed != -1:
                    payload['seed'] = seed
                else:
                    import random
                    payload['seed'] = random.randint(0, 2147483647)
                    print(f"ğŸ² éšæœºç”Ÿæˆç§å­: {payload['seed']}")
                
                # è®¾ç½®è¯·æ±‚å¤´
                headers = {
                    'Authorization': f'Bearer {token}',
                    'Content-Type': 'application/json',
                    'X-ModelScope-Async-Mode': 'true',
                    'X-ModelScope-Task-Type': 'image-to-image-generation',
                    'X-ModelScope-Request-Params': json.dumps({'loras': lora_dict} if lora_dict else {})
                }
                
                print(f"ğŸš€ å‘é€APIè¯·æ±‚åˆ° {model}...")
                url = 'https://api-inference.modelscope.cn/v1/images/generations'
                submission_response = requests.post(
                    url,
                    data=json.dumps(payload, ensure_ascii=False).encode('utf-8'),
                    headers=headers,
                    timeout=config.get("timeout", 60)
                )
                
                if submission_response.status_code != 200:
                    raise Exception(f"APIè¯·æ±‚å¤±è´¥: {submission_response.status_code}, {submission_response.text}")
                
                submission_json = submission_response.json()
                result_image_url = None
                
                if 'task_id' in submission_json:
                    task_id = submission_json['task_id']
                    print(f"ğŸ“Œ è·å–ä»»åŠ¡ID: {task_id}, å¼€å§‹è½®è¯¢ç»“æœ...")
                    poll_start = time.time()
                    max_wait_seconds = max(60, config.get('timeout', 720))
                    
                    while True:
                        task_resp = requests.get(
                            f"https://api-inference.modelscope.cn/v1/tasks/{task_id}",
                            headers={
                                'Authorization': f'Bearer {token}',
                                'X-ModelScope-Task-Type': 'image_generation'
                            },
                            timeout=config.get("image_download_timeout", 120)
                        )
                        
                        if task_resp.status_code != 200:
                            raise Exception(f"ä»»åŠ¡æŸ¥è¯¢å¤±è´¥: {task_resp.status_code}, {task_resp.text}")
                        
                        task_data = task_resp.json()
                        status = task_data.get('task_status')
                        print(f"âŒ› ä»»åŠ¡çŠ¶æ€: {status} (å·²ç­‰å¾… {int(time.time() - poll_start)} ç§’)")
                        
                        if status == 'SUCCEED':
                            output_images = task_data.get('output_images') or []
                            if not output_images:
                                raise Exception("ä»»åŠ¡æˆåŠŸä½†æœªè¿”å›å›¾ç‰‡URL")
                            result_image_url = output_images[0]
                            print(f"âœ… ä»»åŠ¡å®Œæˆï¼Œè·å–å›¾ç‰‡URL")
                            break
                        if status == 'FAILED':
                            error_message = task_data.get('errors', {}).get('message', 'æœªçŸ¥é”™è¯¯')
                            error_code = task_data.get('errors', {}).get('code', 'æœªçŸ¥é”™è¯¯ç ')
                            raise Exception(f"ä»»åŠ¡å¤±è´¥: é”™è¯¯ç  {error_code}, é”™è¯¯ä¿¡æ¯: {error_message}")
                        if time.time() - poll_start > max_wait_seconds:
                            raise Exception(f"ä»»åŠ¡è½®è¯¢è¶…æ—¶ ({max_wait_seconds}ç§’)ï¼Œè¯·ç¨åé‡è¯•æˆ–é™ä½å¹¶å‘")
                        time.sleep(5)
                else:
                    raise Exception(f"æœªè¯†åˆ«çš„APIè¿”å›æ ¼å¼: {submission_json}")
                
                print(f"ğŸ“¥ ä¸‹è½½ç¼–è¾‘åçš„å›¾ç‰‡...")
                img_response = requests.get(result_image_url, timeout=config.get("image_download_timeout", 30))
                if img_response.status_code != 200:
                    raise Exception(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_response.status_code}")
                
                print(f"ğŸ–¼ï¸ å¤„ç†å›¾ç‰‡æ•°æ®...")
                pil_image = Image.open(BytesIO(img_response.content))
                if pil_image.mode != 'RGB':
                    pil_image = pil_image.convert('RGB')
                
                image_np = np.array(pil_image).astype(np.float32) / 255.0
                image_tensor = torch.from_numpy(image_np)[None,]
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if temp_img_path and os.path.exists(temp_img_path):
                    try:
                        os.remove(temp_img_path)
                        print(f"ğŸ§¹ å·²åˆ é™¤ä¸´æ—¶å›¾åƒæ–‡ä»¶")
                    except:
                        print(f"âš ï¸ æ— æ³•åˆ é™¤ä¸´æ—¶å›¾åƒæ–‡ä»¶ {temp_img_path}")
                
                print(f"âœ… ç¬¬ {i+1} ä¸ªTokenè°ƒç”¨æˆåŠŸï¼Œå›¾åƒç¼–è¾‘å®Œæˆ!")
                return (image_tensor,)
                
            except Exception as e:
                last_exception = e
                print(f"âŒ ç¬¬ {i+1} ä¸ªTokenè°ƒç”¨å¤±è´¥: {str(e)}")
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if temp_img_path and os.path.exists(temp_img_path):
                    try:
                        os.remove(temp_img_path)
                    except:
                        pass
                if i < len(tokens) - 1:
                    print(f"â³ å‡†å¤‡å°è¯•ä¸‹ä¸€ä¸ªToken...")
                    continue
                else:
                    break
        
        raise Exception(f"æ‰€æœ‰ {len(tokens)} ä¸ªAPI Tokenéƒ½å¤±è´¥äº†ã€‚æœ€åçš„é”™è¯¯: {str(last_exception)}")

# -------------------------- èŠ‚ç‚¹æ˜ å°„ --------------------------
NODE_CLASS_MAPPINGS = {
    "ModelScopeImageNode": ModelScopeImageNode,
    "ModelScopeImageEditNode": ModelScopeImageEditNode,
    "ModelScopeLoraPresetNode": ModelScopeLoraPresetNode,
    "ModelScopeSingleLoraLoaderNode": ModelScopeSingleLoraLoaderNode,
    "ModelScopeMultiLoraLoaderNode": ModelScopeMultiLoraLoaderNode
}
 
NODE_DISPLAY_NAME_MAPPINGS = {
    "ModelScopeImageNode": "ModelScope-Image ç”Ÿå›¾èŠ‚ç‚¹",
    "ModelScopeImageEditNode": "ModelScope-Image å›¾åƒç¼–è¾‘èŠ‚ç‚¹",
    "ModelScopeLoraPresetNode": "ModelScope-LoRA é¢„è®¾ç®¡ç†",
    "ModelScopeSingleLoraLoaderNode": "ModelScope-LoRA å•LoRAåŠ è½½",
    "ModelScopeMultiLoraLoaderNode": "ModelScope-LoRA å¤šLoRAåŠ è½½"
}